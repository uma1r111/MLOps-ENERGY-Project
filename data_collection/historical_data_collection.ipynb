{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4839a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee71404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1Ô∏è‚É£ HISTORICAL WEATHER DATA (3 months) ----------\n",
    "def fetch_historical_weather(lat=51.5072, lon=-0.1276):\n",
    "    \"\"\"Fetch past 92 days of weather data using past_days parameter.\"\"\"\n",
    "    url = (\n",
    "        f\"https://api.open-meteo.com/v1/forecast?\"\n",
    "        f\"latitude={lat}&longitude={lon}\"\n",
    "        f\"&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m,\"\n",
    "        f\"cloudcover,shortwave_radiation\"\n",
    "        f\"&past_days=92\"\n",
    "    )\n",
    "\n",
    "    print(\"Fetching historical weather data (past 92 days)...\")\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    df_weather = pd.DataFrame(\n",
    "        {\n",
    "            \"datetime\": data[\"hourly\"][\"time\"],\n",
    "            \"temperature_C\": data[\"hourly\"][\"temperature_2m\"],\n",
    "            \"humidity_%\": data[\"hourly\"][\"relative_humidity_2m\"],\n",
    "            \"wind_speed_mps\": data[\"hourly\"][\"wind_speed_10m\"],\n",
    "            \"cloud_cover_%\": data[\"hourly\"][\"cloudcover\"],\n",
    "            \"solar_radiation_Wm2\": data[\"hourly\"][\"shortwave_radiation\"],\n",
    "        }\n",
    "    )\n",
    "    df_weather[\"datetime\"] = pd.to_datetime(df_weather[\"datetime\"])\n",
    "    print(f\"Weather data: {len(df_weather)} records\")\n",
    "    return df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2Ô∏è‚É£ HISTORICAL AIR QUALITY DATA (3 months) ----------\n",
    "def fetch_historical_air_quality(lat=51.5072, lon=-0.1276):\n",
    "    \"\"\"Fetch past 92 days of air quality data using past_days parameter.\"\"\"\n",
    "    url = (\n",
    "        f\"https://air-quality-api.open-meteo.com/v1/air-quality?\"\n",
    "        f\"latitude={lat}&longitude={lon}\"\n",
    "        f\"&hourly=pm10,pm2_5,carbon_monoxide,nitrogen_dioxide,\"\n",
    "        f\"sulphur_dioxide,ozone,us_aqi\"\n",
    "        f\"&past_days=92\"\n",
    "    )\n",
    "\n",
    "    print(\"Fetching historical air quality data (past 92 days)...\")\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    df_aqi = pd.DataFrame(\n",
    "        {\n",
    "            \"datetime\": pd.to_datetime(data[\"hourly\"][\"time\"]),\n",
    "            \"pm10\": data[\"hourly\"][\"pm10\"],\n",
    "            \"pm2_5\": data[\"hourly\"][\"pm2_5\"],\n",
    "            \"co\": data[\"hourly\"][\"carbon_monoxide\"],\n",
    "            \"no2\": data[\"hourly\"][\"nitrogen_dioxide\"],\n",
    "            \"so2\": data[\"hourly\"][\"sulphur_dioxide\"],\n",
    "            \"o3\": data[\"hourly\"][\"ozone\"],\n",
    "            \"aqi_us\": data[\"hourly\"][\"us_aqi\"],\n",
    "        }\n",
    "    )\n",
    "    print(f\"Air quality data: {len(df_aqi)} records\")\n",
    "    return df_aqi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00889dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_historical_carbon_intensity():\n",
    "    \"\"\"Fetch past 3 months of UK carbon intensity data.\"\"\"\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=92)\n",
    "\n",
    "    all_data = []\n",
    "    current_date = start_date\n",
    "\n",
    "    print(\"Fetching historical carbon intensity (past 92 days)...\")\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        month_end = min(current_date + timedelta(days=30), end_date)\n",
    "        date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "        end_str = month_end.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        url = f\"https://api.carbonintensity.org.uk/intensity/{date_str}/{end_str}\"\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json().get(\"data\", [])\n",
    "\n",
    "            for r in data:\n",
    "                all_data.append(\n",
    "                    {\n",
    "                        \"datetime\": r.get(\"from\"),\n",
    "                        \"carbon_intensity_actual\": r.get(\"intensity\", {}).get(\"actual\"),\n",
    "                        \"carbon_intensity_forecast\": r.get(\"intensity\", {}).get(\n",
    "                            \"forecast\"\n",
    "                        ),\n",
    "                        \"carbon_index\": r.get(\"intensity\", {}).get(\"index\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error fetching {url}: {e}\")\n",
    "            continue\n",
    "\n",
    "        current_date = month_end + timedelta(days=1)\n",
    "\n",
    "    df_carbon = pd.DataFrame(all_data)\n",
    "    df_carbon[\"datetime\"] = pd.to_datetime(df_carbon[\"datetime\"])\n",
    "    print(f\"Carbon intensity data: {len(df_carbon)} records\")\n",
    "    return df_carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f36a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_historical_generation_mix():\n",
    "    \"\"\"Fetch generation mix data (sampled every 12 hours for past 92 days).\"\"\"\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=92)\n",
    "\n",
    "    all_data = []\n",
    "    sample_dates = pd.date_range(start=start_date, end=end_date, freq=\"12h\")\n",
    "\n",
    "    print(\"Fetching historical generation mix (sampled)...\")\n",
    "\n",
    "    for i, dt in enumerate(sample_dates, 1):\n",
    "        print(\n",
    "            f\"  üîÑ Fetching generation mix {i}/{len(sample_dates)} for {dt.strftime('%Y-%m-%d %H:%M')}...\"\n",
    "        )\n",
    "        date_str = dt.strftime(\"%Y-%m-%dT%H:%MZ\")\n",
    "        url = f\"https://api.carbonintensity.org.uk/generation/{date_str}/pt24h\"\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json().get(\"data\", [])\n",
    "\n",
    "                for record in data:\n",
    "                    timestamp = record.get(\"from\")\n",
    "                    gen_mix = record.get(\"generationmix\", [])\n",
    "\n",
    "                    mix_dict = {\"datetime\": timestamp}\n",
    "                    for item in gen_mix:\n",
    "                        fuel = item[\"fuel\"].lower().replace(\" \", \"_\")\n",
    "                        mix_dict[f\"uk_gen_{fuel}_%\"] = item[\"perc\"]\n",
    "\n",
    "                    all_data.append(mix_dict)\n",
    "\n",
    "            time.sleep(0.3)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipped {dt.strftime('%Y-%m-%d %H:%M')} ‚Äî {e}\")\n",
    "            continue\n",
    "\n",
    "    df_gen = pd.DataFrame(all_data)\n",
    "    if not df_gen.empty:\n",
    "        df_gen[\"datetime\"] = pd.to_datetime(df_gen[\"datetime\"])\n",
    "    print(f\"‚úÖ Generation mix data fetched: {len(df_gen)} records\")\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f76d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_historical_octopus_prices():\n",
    "    \"\"\"Fetch past 3 months of Octopus Energy prices.\"\"\"\n",
    "    products_url = \"https://api.octopus.energy/v1/products/\"\n",
    "    response = requests.get(products_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    products_data = response.json()\n",
    "    agile_products = [\n",
    "        p for p in products_data.get(\"results\", []) if \"AGILE\" in p[\"code\"]\n",
    "    ]\n",
    "\n",
    "    if not agile_products:\n",
    "        raise ValueError(\"No Agile tariffs found\")\n",
    "\n",
    "    latest_agile = agile_products[0]\n",
    "    product_code = latest_agile[\"code\"]\n",
    "\n",
    "    tariff_code = None\n",
    "    for link in latest_agile.get(\"links\", []):\n",
    "        if \"electricity-tariffs\" in link.get(\"href\", \"\"):\n",
    "            tariff_code = link[\"href\"].split(\"/\")[-2]\n",
    "            break\n",
    "    if not tariff_code:\n",
    "        tariff_code = f\"E-1R-{product_code}-A\"\n",
    "\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=92)\n",
    "\n",
    "    period_from = start_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    period_to = end_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    url = (\n",
    "        f\"https://api.octopus.energy/v1/products/{product_code}/\"\n",
    "        f\"electricity-tariffs/{tariff_code}/standard-unit-rates/\"\n",
    "        f\"?period_from={period_from}&period_to={period_to}\"\n",
    "        f\"&page_size=1500\"\n",
    "    )\n",
    "\n",
    "    print(\"Fetching historical Octopus prices (past 92 days)...\")\n",
    "\n",
    "    all_prices = []\n",
    "    while url:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            results = data.get(\"results\", [])\n",
    "            all_prices.extend(results)\n",
    "\n",
    "            url = data.get(\"next\")\n",
    "            if url:\n",
    "                time.sleep(0.3)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error fetching Octopus prices: {e}\")\n",
    "            break\n",
    "\n",
    "    df_prices = pd.DataFrame(all_prices)\n",
    "    df_prices[\"datetime\"] = pd.to_datetime(df_prices[\"valid_from\"])\n",
    "    df_prices[\"retail_price_¬£_per_kWh\"] = df_prices[\"value_inc_vat\"] / 100\n",
    "    df_prices = df_prices[[\"datetime\", \"retail_price_¬£_per_kWh\"]]\n",
    "    print(f\"Electricity prices: {len(df_prices)} records\")\n",
    "    return df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf061b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 6Ô∏è‚É£ MERGE ALL SOURCES ----------\n",
    "def merge_all_sources(weather_df, aqi_df, carbon_df, carbon_gen_df, prices_df):\n",
    "    \"\"\"Merge all data sources on datetime (normalize to UTC).\"\"\"\n",
    "    dfs = [weather_df, aqi_df, carbon_df, prices_df]\n",
    "\n",
    "    for df in dfs:\n",
    "        if df[\"datetime\"].dt.tz is None:\n",
    "            df[\"datetime\"] = df[\"datetime\"].dt.tz_localize(\"UTC\")\n",
    "        else:\n",
    "            df[\"datetime\"] = df[\"datetime\"].dt.tz_convert(\"UTC\")\n",
    "\n",
    "    merged = weather_df.merge(aqi_df, on=\"datetime\", how=\"outer\")\n",
    "    merged = merged.merge(carbon_df, on=\"datetime\", how=\"outer\")\n",
    "    merged = merged.merge(prices_df, on=\"datetime\", how=\"outer\")\n",
    "\n",
    "    if not carbon_gen_df.empty:\n",
    "        if carbon_gen_df[\"datetime\"].dt.tz is None:\n",
    "            carbon_gen_df[\"datetime\"] = carbon_gen_df[\"datetime\"].dt.tz_localize(\"UTC\")\n",
    "        else:\n",
    "            carbon_gen_df[\"datetime\"] = carbon_gen_df[\"datetime\"].dt.tz_convert(\"UTC\")\n",
    "\n",
    "        merged = merged.merge(carbon_gen_df, on=\"datetime\", how=\"left\")\n",
    "\n",
    "        for col in carbon_gen_df.columns:\n",
    "            if col != \"datetime\" and col in merged.columns:\n",
    "                merged[col] = merged[col].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "    merged = merged.sort_values(\"datetime\").reset_index(drop=True)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9773ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 7Ô∏è‚É£ MAIN COLLECTION ----------\n",
    "def collect_historical_data(save_dir=\"data\", file_name=\"uk_energy_data.csv\"):\n",
    "    \"\"\"\n",
    "    Collect 3 months of historical data.\n",
    "    Saves to the same file that daily collection will append to.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        weather_df = fetch_historical_weather()\n",
    "        aqi_df = fetch_historical_air_quality()\n",
    "        carbon_df = fetch_historical_carbon_intensity()\n",
    "        carbon_gen_df = fetch_historical_generation_mix()\n",
    "        prices_df = fetch_historical_octopus_prices()\n",
    "\n",
    "        print(\"\\nMerging all datasets...\")\n",
    "        merged_df = merge_all_sources(\n",
    "            weather_df, aqi_df, carbon_df, carbon_gen_df, prices_df\n",
    "        )\n",
    "\n",
    "        # --- üßπ Clean up duplicate & half-hour entries ---\n",
    "        merged_df[\"datetime\"] = pd.to_datetime(merged_df[\"datetime\"])\n",
    "\n",
    "        # Round timestamps down to the nearest hour (drops 30-min marks)\n",
    "        merged_df[\"datetime\"] = merged_df[\"datetime\"].dt.floor(\"H\")\n",
    "\n",
    "        # Drop duplicate timestamps (keep first)\n",
    "        merged_df = merged_df.drop_duplicates(subset=[\"datetime\"], keep=\"first\")\n",
    "\n",
    "        # Sort by datetime and reset index\n",
    "        merged_df = merged_df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "        merged_df.to_csv(save_path, index=False)\n",
    "        print(f\"\\nHistorical data saved to: {save_path}\")\n",
    "        print(f\"Total records: {len(merged_df)}\")\n",
    "        print(\n",
    "            f\"Date range: {merged_df['datetime'].min()} to {merged_df['datetime'].max()}\"\n",
    "        )\n",
    "\n",
    "        return merged_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during historical data collection: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = collect_historical_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
